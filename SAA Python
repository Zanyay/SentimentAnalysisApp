import re
from collections import defaultdict
from typing import List, Dict, Tuple
import tkinter as tk
from tkinter import messagebox, filedialog
from tkinter import ttk
import speech_recognition as sr
from pathlib import Path

class SentimentAnalyzer:
    def __init__(self):
        self.sentiment_data = {
            'positive': [],
            'neutral': [],
            'negative': []
        }
        self.ngram_counts = {
            'bigram': defaultdict(lambda: defaultdict(int)),
            'trigram': defaultdict(lambda: defaultdict(int))
        }
        self.load_training_data()
        self.train()

    def load_training_data(self):
        # Load training data from file
        training_data = [
            ("I absolutely love this product!", "positive"),
            ("This is the best day ever!", "positive"),
            ("Great service and amazing quality", "positive"),
            ("The weather is okay today", "neutral"),
            ("I'm not sure how I feel about this", "neutral"),
            ("It could be better but it's not terrible", "neutral"),
            ("This is terrible, I hate it", "negative"),
            ("Worst experience ever, very disappointing", "negative"),
            ("Poor quality and bad service", "negative"),
            ("I love my phone", "positive"),
            ("I hate my phone", "negative"),
            ("My phone is okay", "neutral"),
            ("I am very happy with my purchase", "positive"),
            ("I am very unhappy with my purchase", "negative"),
            ("The product is average", "neutral")
        ]

        for text, sentiment in training_data:
            self.sentiment_data[sentiment].append(text.lower())

    def preprocess_text(self, text: str) -> str:
        # Clean and preprocess text
        text = text.lower()
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        return text

    def get_ngrams(self, text: str, n: int) -> List[str]:
        # Generate n-grams from text
        words = self.preprocess_text(text).split()
        ngrams = []
        for i in range(len(words) - n + 1):
            ngram = ' '.join(words[i:i + n])
            ngrams.append(ngram)
        return ngrams

    def train(self):
        # Train the model using bigrams and trigrams
        for sentiment, texts in self.sentiment_data.items():
            for text in texts:
                # Process bigrams
                bigrams = self.get_ngrams(text, 2)
                for bigram in bigrams:
                    self.ngram_counts['bigram'][sentiment][bigram] += 1

                # Process trigrams
                trigrams = self.get_ngrams(text, 3)
                for trigram in trigrams:
                    self.ngram_counts['trigram'][sentiment][trigram] += 1

    def analyze_sentiment(self, text: str) -> Dict[str, float]:
        # Analyze sentiment of input text
        bigrams = self.get_ngrams(text, 2)
        trigrams = self.get_ngrams(text, 3)
        
        scores = {
            'positive': 0.0,
            'neutral': 0.0,
            'negative': 0.0
        }

        # Weight for combining bigram and trigram scores
        bigram_weight = 0.75
        trigram_weight = 0.25

        # Calculate bigram scores
        for bigram in bigrams:
            for sentiment in scores.keys():
                if bigram in self.ngram_counts['bigram'][sentiment]:
                    scores[sentiment] += self.ngram_counts['bigram'][sentiment][bigram] * bigram_weight

        # Calculate trigram scores
        for trigram in trigrams:
            for sentiment in scores.keys():
                if trigram in self.ngram_counts['trigram'][sentiment]:
                    scores[sentiment] += self.ngram_counts['trigram'][sentiment][trigram] * trigram_weight

        # Fallback mechanism if no n-grams match
        if sum(scores.values()) == 0:
            scores['neutral'] = 1.0

        # Normalize scores
        total_score = sum(scores.values()) or 1
        normalized_scores = {
            sentiment: (score / total_score) * 100 
            for sentiment, score in scores.items()
        }

        return normalized_scores

    def get_final_sentiment(self, scores: Dict[str, float]) -> Tuple[str, float]:
        # Determine final sentiment based on highest score
        final_sentiment = max(scores.items(), key=lambda x: x[1])
        return final_sentiment

    def add_to_training_data(self, text: str, sentiment: str):
        # Add new text to training data and retrain the model
        self.sentiment_data[sentiment].append(text.lower())
        self.train()

    def export_training_data(self, filepath: str):
        # Export training data to a file
        with open(filepath, 'w') as file:
            for sentiment, texts in self.sentiment_data.items():
                for text in texts:
                    file.write(f"{text}\t{sentiment}\n")

    def import_training_data(self, filepath: str):
        # Import training data from a file
        with open(filepath, 'r') as file:
            for line in file:
                text, sentiment = line.strip().split('\t')
                self.sentiment_data[sentiment].append(text.lower())
        self.train()

    def get_training_data(self) -> List[Tuple[str, str]]:
        # Get the training data as a list of tuples
        training_data = []
        for sentiment, texts in self.sentiment_data.items():
            for text in texts:
                training_data.append((text, sentiment))
        return training_data

def analyze_text():
    global last_analyzed_text
    text = text_entry.get("1.0", tk.END).strip()
    if not text:
        messagebox.showwarning("Input Error", "Please enter some text to analyze.")
        return

    # Analyze sentiment
    scores = analyzer.analyze_sentiment(text)
    final_sentiment, confidence = analyzer.get_final_sentiment(scores)

    # Display results
    result_text = f"Sentiment Analysis Results:\n{'-' * 25}\nText: {text}\n\nDetailed Scores:\n"
    for sentiment, score in scores.items():
        result_text += f"{sentiment.capitalize()}: {score:.2f}%\n"
    result_text += f"\nFinal Sentiment: {final_sentiment.capitalize()} (Confidence: {confidence:.2f}%)"
    result_label.config(text=result_text)

    # Store the last analyzed text
    last_analyzed_text = text

    # Clear the text box
    text_entry.delete("1.0", tk.END)

def add_to_training():
    global last_analyzed_text
    if not last_analyzed_text:
        messagebox.showwarning("Input Error", "No text has been analyzed yet.")
        return

    sentiment = sentiment_var.get()
    if sentiment not in ['positive', 'neutral', 'negative']:
        messagebox.showwarning("Input Error", "Please select a sentiment.")
        return

    analyzer.add_to_training_data(last_analyzed_text, sentiment)
    messagebox.showinfo("Success", "Text added to training data successfully.")
    update_training_data_view()

def export_training_data():
    filepath = filedialog.asksaveasfilename(defaultextension=".txt", filetypes=[("Text files", "*.txt")])
    if filepath:
        analyzer.export_training_data(filepath)
        messagebox.showinfo("Success", "Training data exported successfully.")

def import_training_data():
    filepath = filedialog.askopenfilename(filetypes=[("Text files", "*.txt")])
    if filepath:
        analyzer.import_training_data(filepath)
        messagebox.showinfo("Success", "Training data imported successfully.")
        update_training_data_view()

def update_training_data_view():
    training_data = analyzer.get_training_data()
    training_data_text = "\n".join([f"{text} - {sentiment}" for text, sentiment in training_data])
    training_data_textbox.config(state=tk.NORMAL)
    training_data_textbox.delete("1.0", tk.END)
    training_data_textbox.insert(tk.END, training_data_text)
    training_data_textbox.config(state=tk.DISABLED)

# Initialize analyzer
analyzer = SentimentAnalyzer()
last_analyzed_text = ""

# Create the main window
root = tk.Tk()
root.title("Sentiment Analyzer")

# Create a tabbed interface
tab_control = ttk.Notebook(root)
tab1 = ttk.Frame(tab_control)
tab2 = ttk.Frame(tab_control)
tab3 = ttk.Frame(tab_control)
tab_control.add(tab3, text="Audio Analysis")      # Changed order - Audio first
tab_control.add(tab1, text="Text Analysis")  # Text analysis second
tab_control.add(tab2, text="Training Data")       # Training data last
tab_control.pack(expand=1, fill="both")

# Tab 1: Sentiment Analysis
tk.Label(tab1, text="Enter text to analyze:").pack(pady=10)
text_entry = tk.Text(tab1, height=10, width=50)
text_entry.pack(pady=10)
analyze_button = tk.Button(tab1, text="Analyze Sentiment", command=analyze_text)
analyze_button.pack(pady=10)

result_label = tk.Label(tab1, text="", justify=tk.LEFT)
result_label.pack(pady=10)

# Create a frame for the buttons and sentiment selection
top_frame = tk.Frame(tab1)
top_frame.pack(pady=10)

# Add text above the sentiment selection
tk.Label(top_frame, text="Add results to training data as:").pack(side=tk.TOP)

# Add sentiment selection for training data
sentiment_var = tk.StringVar(value="neutral")
tk.Radiobutton(top_frame, text="Positive", variable=sentiment_var, value="positive").pack(side=tk.TOP)
tk.Radiobutton(top_frame, text="Neutral", variable=sentiment_var, value="neutral").pack(side=tk.TOP)
tk.Radiobutton(top_frame, text="Negative", variable=sentiment_var, value="negative").pack(side=tk.TOP)

add_button = tk.Button(top_frame, text="Add results", command=add_to_training)
add_button.pack(side=tk.TOP, pady=5)

# Create a frame for the import and export buttons at the bottom
bottom_frame = tk.Frame(tab1)
bottom_frame.pack(side=tk.BOTTOM, pady=10)

import_export_frame = tk.Frame(bottom_frame)
import_export_frame.pack(side=tk.TOP, pady=5)

export_button = tk.Button(import_export_frame, text="Export Training Data", command=export_training_data)
export_button.pack(side=tk.LEFT, padx=5)

import_button = tk.Button(import_export_frame, text="Import Training Data", command=import_training_data)
import_button.pack(side=tk.LEFT, padx=5)

# Tab 2: Training Data
training_data_textbox = tk.Text(tab2, height=20, width=80, state=tk.DISABLED)
training_data_textbox.pack(pady=10)

# Update the training data view initially
update_training_data_view()

def process_audio_file():
    file_path = filedialog.askopenfilename(
        filetypes=[("Audio Files", "*.wav *.mp3 *.ogg *.m4a")]  # Allow more audio formats
    )
    if not file_path:
        return
    
    # Check if file exists
    if not Path(file_path).exists():
        messagebox.showerror("Error", f"File not found: {file_path}")
        audio_status_label.config(text="Error: File not found")
        return
        
    # Debug info
    print(f"Selected file: {file_path}")
    print(f"File exists: {Path(file_path).exists()}")
    print(f"File size: {Path(file_path).stat().st_size} bytes")
    
    audio_status_label.config(text=f"Processing audio file: {Path(file_path).name}")
    root.update()
    
    try:
        # Initialize recognizer with specific settings
        r = sr.Recognizer()
        r.energy_threshold = 4000
        r.dynamic_energy_threshold = True
        
        # Load the audio file
        try:
            with sr.AudioFile(file_path) as source:
                print("Audio file opened successfully")
                # Adjust for ambient noise
                r.adjust_for_ambient_noise(source)
                print("Ambient noise adjustment complete")
                audio = r.record(source)
                print("Audio recording complete")
        except Exception as e:
            print(f"Error opening audio file: {str(e)}")
            raise
            
        try:
            # Convert speech to text
            text = r.recognize_google(audio)
            
            # Display the transcribed text
            audio_text_display.config(state=tk.NORMAL)
            audio_text_display.delete(1.0, tk.END)
            audio_text_display.insert(tk.END, text)
            audio_text_display.config(state=tk.DISABLED)
            
            # Only proceed with sentiment analysis if we have text
            if text.strip():
                # Analyze sentiment
                scores = analyzer.analyze_sentiment(text)
                final_sentiment, confidence = analyzer.get_final_sentiment(scores)
                
                # Display results
                result_text = f"Sentiment Analysis Results:\n{'-' * 25}\n\nDetailed Scores:\n"
                for sentiment, score in scores.items():
                    result_text += f"{sentiment.capitalize()}: {score:.2f}%\n"
                result_text += f"\nFinal Sentiment: {final_sentiment.capitalize()} (Confidence: {confidence:.2f}%)"
                
                audio_result_label.config(text=result_text)
                audio_status_label.config(text="Analysis complete!")
            else:
                audio_status_label.config(text="No speech detected in audio")
                
        except sr.UnknownValueError:
            messagebox.showerror("Error", "Could not understand the audio. Please ensure the audio is clear and contains speech.")
            audio_status_label.config(text="Error: Could not understand the audio")
        except sr.RequestError as e:
            messagebox.showerror("Error", f"Could not connect to the speech recognition service: {str(e)}")
            audio_status_label.config(text="Error: Service connection failed")
            
    except Exception as e:
        messagebox.showerror("Error", f"An error occurred while processing the audio file: {str(e)}")
        audio_status_label.config(text="Error: Processing failed")
        print(f"Detailed error: {str(e)}")  # For debugging

# Tab 3: Audio Analysis
tk.Label(tab3, text="Select an audio file for analysis:").pack(pady=10)
audio_button = tk.Button(tab3, text="Choose Audio File", command=process_audio_file)
audio_button.pack(pady=10)

audio_status_label = tk.Label(tab3, text="No file selected")
audio_status_label.pack(pady=5)

tk.Label(tab3, text="Transcribed Text:").pack(pady=5)
audio_text_display = tk.Text(tab3, height=8, width=50, state=tk.DISABLED)
audio_text_display.pack(pady=10)

audio_result_label = tk.Label(tab3, text="", justify=tk.LEFT)
audio_result_label.pack(pady=10)

# Add training controls to Audio tab
audio_top_frame = tk.Frame(tab3)
audio_top_frame.pack(pady=10)

# Add text above the sentiment selection
tk.Label(audio_top_frame, text="Add results to training data as:").pack(side=tk.TOP)

# Add sentiment selection for training data
audio_sentiment_var = tk.StringVar(value="neutral")
tk.Radiobutton(audio_top_frame, text="Positive", variable=audio_sentiment_var, value="positive").pack(side=tk.TOP)
tk.Radiobutton(audio_top_frame, text="Neutral", variable=audio_sentiment_var, value="neutral").pack(side=tk.TOP)
tk.Radiobutton(audio_top_frame, text="Negative", variable=audio_sentiment_var, value="negative").pack(side=tk.TOP)

audio_add_button = tk.Button(audio_top_frame, text="Add results", command=lambda: add_to_training_from_audio())
audio_add_button.pack(side=tk.TOP, pady=5)

# Create a frame for the import and export buttons at the bottom
audio_bottom_frame = tk.Frame(tab3)
audio_bottom_frame.pack(side=tk.BOTTOM, pady=10)

audio_import_export_frame = tk.Frame(audio_bottom_frame)
audio_import_export_frame.pack(side=tk.TOP, pady=5)

audio_export_button = tk.Button(audio_import_export_frame, text="Export Training Data", command=export_training_data)
audio_export_button.pack(side=tk.LEFT, padx=5)

audio_import_button = tk.Button(audio_import_export_frame, text="Import Training Data", command=import_training_data)
audio_import_button.pack(side=tk.LEFT, padx=5)

# Add new function to handle adding audio transcription to training data
def add_to_training_from_audio():
    text = audio_text_display.get("1.0", tk.END).strip()
    if not text:
        messagebox.showwarning("Input Error", "No text has been transcribed yet.")
        return

    sentiment = audio_sentiment_var.get()
    if sentiment not in ['positive', 'neutral', 'negative']:
        messagebox.showwarning("Input Error", "Please select a sentiment.")
        return

    analyzer.add_to_training_data(text, sentiment)
    messagebox.showinfo("Success", "Text added to training data successfully.")
    update_training_data_view()

def create_about_tab(tab):
    # Create a scrollable frame
    canvas = tk.Canvas(tab)
    scrollbar = ttk.Scrollbar(tab, orient="vertical", command=canvas.yview)
    scrollable_frame = ttk.Frame(canvas)

    scrollable_frame.bind(
        "<Configure>",
        lambda e: canvas.configure(scrollregion=canvas.bbox("all"))
    )

    canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
    canvas.configure(yscrollcommand=scrollbar.set)

    # Title
    title = ttk.Label(
        scrollable_frame,
        text="About the Sentiment Analyzer",
        font=("Helvetica", 14, "bold")
    )
    title.pack(pady=10)

    # What is Sentiment Analysis section
    what_is = ttk.LabelFrame(scrollable_frame, text="What is Sentiment Analysis?")
    ttk.Label(
        what_is,
        text="Sentiment analysis is the process of determining the emotional tone behind "
             "a piece of text. This tool provides two different approaches to sentiment analysis:",
        wraplength=500
    ).pack(pady=5)
    
    approaches = ttk.Frame(what_is)
    ttk.Label(approaches, text="• Naive Bayes Classification (word-based)").pack(anchor="w")
    ttk.Label(approaches, text="• N-gram Analysis (phrase-based)").pack(anchor="w")
    approaches.pack(pady=5)
    what_is.pack(fill="x", padx=10, pady=5)

    # Naive Bayes Analysis section
    naive_bayes = ttk.LabelFrame(scrollable_frame, text="Naive Bayes Analysis")
    ttk.Label(
        naive_bayes,
        text="The Naive Bayes classifier uses Bayes' Theorem with a \"naive\" assumption "
             "of independence between words. The mathematical formula is:",
        wraplength=500
    ).pack(pady=5)
    
    formula = ttk.Label(
        naive_bayes,
        text="P(class|text) ∝ P(class) × ∏ P(word|class)",
        font=("Courier", 10)
    )
    formula.pack(pady=5)
    
    components = ttk.Frame(naive_bayes)
    ttk.Label(components, text="• P(class) - Prior probability of each class (positive/negative/neutral)").pack(anchor="w")
    ttk.Label(components, text="• P(word|class) - Probability of each word appearing in a given class").pack(anchor="w")
    ttk.Label(components, text="• ∏ - Product of all word probabilities").pack(anchor="w")
    components.pack(pady=5)
    naive_bayes.pack(fill="x", padx=10, pady=5)

    # N-gram Analysis section
    ngram = ttk.LabelFrame(scrollable_frame, text="N-gram Analysis")
    ttk.Label(
        ngram,
        text="N-gram analysis extends beyond individual words to consider sequences of N consecutive words:",
        wraplength=500
    ).pack(pady=5)
    
    ngram_types = ttk.Frame(ngram)
    ttk.Label(ngram_types, text="• Unigrams (N=1): Individual words").pack(anchor="w")
    ttk.Label(ngram_types, text="• Bigrams (N=2): Pairs of consecutive words").pack(anchor="w")
    ttk.Label(ngram_types, text="• Trigrams (N=3): Sequences of three consecutive words").pack(anchor="w")
    ngram_types.pack(pady=5)
    ngram.pack(fill="x", padx=10, pady=5)

    # Key Features section
    features = ttk.LabelFrame(scrollable_frame, text="Key Features")
    features_list = [
        "• Dual analysis methods (Naive Bayes and N-grams)",
        "• Laplace (add-one) smoothing for both approaches",
        "• Log probabilities to prevent numerical underflow",
        "• Confidence scores using probability normalization",
        "• Interactive training data management",
        "• CSV import/export capabilities",
        "• Detailed probability calculations view"
    ]
    for feature in features_list:
        ttk.Label(features, text=feature).pack(anchor="w")
    features.pack(fill="x", padx=10, pady=5)

    # Text Processing section
    processing = ttk.LabelFrame(scrollable_frame, text="Text Processing")
    process_steps = [
        "1. Text is converted to lowercase",
        "2. Punctuation is removed",
        "3. Text is split into tokens (words or n-grams)",
        "4. Empty tokens are filtered out"
    ]
    for step in process_steps:
        ttk.Label(processing, text=step).pack(anchor="w")
    processing.pack(fill="x", padx=10, pady=5)

    # Training Process section
    training = ttk.LabelFrame(scrollable_frame, text="Training Process")
    train_steps = [
        "1. Count occurrences of tokens in each class",
        "2. Calculate prior probabilities for each class",
        "3. Apply Laplace smoothing to token probabilities",
        "4. Store model parameters for both analysis methods"
    ]
    for step in train_steps:
        ttk.Label(training, text=step).pack(anchor="w")
    training.pack(fill="x", padx=10, pady=5)

    # Prediction Process section
    prediction = ttk.LabelFrame(scrollable_frame, text="Prediction Process")
    pred_steps = [
        "1. Preprocess input text",
        "2. Generate appropriate tokens (words or n-grams)",
        "3. Calculate log probabilities for each class",
        "4. Sum log probabilities of tokens and prior",
        "5. Convert to normalized confidence scores",
        "6. Select class with highest probability"
    ]
    for step in pred_steps:
        ttk.Label(prediction, text=step).pack(anchor="w")
    prediction.pack(fill="x", padx=10, pady=5)

    # Pack the canvas and scrollbar
    canvas.pack(side="left", fill="both", expand=True, padx=5, pady=5)
    scrollbar.pack(side="right", fill="y")

# Modify your existing code to add the About tab
tab4 = ttk.Frame(tab_control)
tab_control.add(tab4, text="About")
create_about_tab(tab4)

# Start the main event loop
root.mainloop()